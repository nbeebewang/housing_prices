{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.patches import Polygon\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import cross_validation\n",
    "from sklearn import covariance\n",
    "from sklearn import ensemble\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNN\n",
    "from sklearn.decomposition import PCA\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline\n",
    "import math\n",
    "import string\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_best_features = pd.read_csv(\"train_best_features.csv\")\n",
    "test_best_features = pd.read_csv(\"test_best_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train_best_features.drop(['zestimate_amount'],1)\n",
    "y_train = train_best_features['zestimate_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = test_best_features.drop(['zestimate_amount'],1)\n",
    "y_test = test_best_features['zestimate_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "Trees: 10 Depth: 2 PCA dim:  5 Score: 0.00124246441064\n",
      "Trees: 10 Depth: 2 PCA dim:  6 Score: 0.00124246441064\n",
      "Trees: 10 Depth: 2 PCA dim:  7 Score: 0.00124237305632\n",
      "Trees: 10 Depth: 2 PCA dim:  8 Score: 0.00114690779335\n",
      "Trees: 10 Depth: 2 PCA dim:  9 Score: 0.00143371467671\n"
     ]
    }
   ],
   "source": [
    "# Parameters for tuning\n",
    "n_trees = np.arange(10, 100, 20)  # Trees and depth are explored on an exponentially growing space,\n",
    "depths = np.arange(2, 10)   # since it is assumed that trees and depth will add accuracy in a decaying fashion.\n",
    "pca_dims = range(5,15)\n",
    "\n",
    "# To keep track of the best model\n",
    "best_score = 0\n",
    "# Run grid search for model with 5-fold cross validation\n",
    "print '5-fold cross validation:'\n",
    "for trees in n_trees:\n",
    "    for depth in depths:\n",
    "        for pca_dim in pca_dims:\n",
    "            # Cross validation for every experiment\n",
    "            k_folds = cross_validation.KFold(x_train.shape[0], n_folds=5, shuffle=True)\n",
    "            scores = []\n",
    "            for train_indices, validation_indices in k_folds:\n",
    "                # Generate training data\n",
    "                x_train_cv = x_train.iloc[train_indices].values\n",
    "                y_train_cv = y_train[train_indices].values\n",
    "                # Generate validation data\n",
    "                x_validate = x_train.iloc[validation_indices].values\n",
    "                y_validate = y_train[validation_indices].values\n",
    "\n",
    "                #Project to the data onto axes\n",
    "                pca = PCA(n_components=pca_dim)\n",
    "                pca.fit(x_train_cv)\n",
    "                x_train_reduced = pca.transform(x_train_cv)\n",
    "                x_validate_reduced = pca.transform(x_validate)\n",
    "\n",
    "                # Fit random forest on training data\n",
    "                model = ensemble.RandomForestClassifier(n_estimators=trees, max_depth=depth)\n",
    "                model.fit(x_train_reduced, y_train_cv)\n",
    "                # Score on validation data\n",
    "                scores += [model.score(x_validate_reduced, y_validate)]\n",
    "\n",
    "            # Record and report accuracy\n",
    "            average_score = np.mean(scores)\n",
    "            print \"Trees:\", trees, \"Depth:\", depth, \"PCA dim: \", pca_dim, \"Score:\", average_score\n",
    "\n",
    "            # Update our record of the best parameters see so far\n",
    "            if average_score > best_score:\n",
    "                best_score = average_score\n",
    "                best_trees = trees\n",
    "                best_depth = depth\n",
    "            \n",
    "# Fit model on entire train set using chosen number of trees and depth\n",
    "model = ensemble.RandomForestRegressor(n_estimators=best_trees, max_depth=best_depth)\n",
    "model.fit(x_train, y_train)\n",
    "print 'Chosen number of trees, depth:', best_trees, ',', best_depth\n",
    "print 'Test accuracy:', model.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
